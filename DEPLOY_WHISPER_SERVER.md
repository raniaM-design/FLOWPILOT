# üè† D√©ploiement de votre propre Serveur Whisper pour PILOTYS

## Vue d'ensemble

Ce guide vous explique comment d√©ployer votre propre serveur Whisper pour transcrire les audios de r√©union **100% localement et gratuitement**, avec un contr√¥le total sur vos donn√©es.

## Avantages

‚úÖ **100% gratuit** apr√®s le d√©ploiement initial
‚úÖ **S√©curit√© maximale** : vos donn√©es ne quittent jamais votre infrastructure
‚úÖ **Contr√¥le total** : vous g√©rez le mod√®le, les performances, la confidentialit√©
‚úÖ **Pas de limites** : transcrire autant d'audios que vous voulez
‚úÖ **H√©bergement s√©curis√©** : donn√©es h√©berg√©es en Europe/France si configur√©

## Architecture

```
PILOTYS (Vercel) ‚Üí Votre Serveur Whisper ‚Üí Transcription ‚Üí PILOTYS
```

Votre serveur Whisper peut √™tre h√©berg√© sur :
- Votre propre serveur (VPS, cloud priv√©)
- Un serveur d√©di√© (OVH, Scaleway, AWS, etc.)
- Un conteneur Docker (facile √† d√©ployer)

## Option 1 : D√©ploiement avec Docker (Recommand√© - Le plus simple)

### Pr√©requis

- Un serveur avec Docker install√©
- Au moins 4GB de RAM (8GB recommand√©)
- GPU optionnel mais recommand√© pour la vitesse

### √âtape 1 : Cr√©er le serveur Whisper

Cr√©ez un fichier `whisper-server.py` sur votre serveur :

```python
from flask import Flask, request, jsonify
from flask_cors import CORS
import whisper
import tempfile
import os

app = Flask(__name__)
CORS(app)  # Autoriser les requ√™tes depuis PILOTYS

# Charger le mod√®le Whisper au d√©marrage
print("Chargement du mod√®le Whisper...")
model = whisper.load_model("base")  # ou "small", "medium", "large"
print("Mod√®le Whisper charg√© !")

@app.route("/health", methods=["GET"])
def health():
    return jsonify({"status": "ok", "model": "whisper-base"})

@app.route("/transcribe", methods=["POST"])
def transcribe():
    if "file" not in request.files:
        return jsonify({"error": "Aucun fichier fourni"}), 400
    
    file = request.files["file"]
    
    # Sauvegarder temporairement le fichier
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        file.save(tmp_file.name)
        tmp_path = tmp_file.name
    
    try:
        # Transcrire avec Whisper
        result = model.transcribe(tmp_path, language="fr")
        
        return jsonify({
            "text": result["text"],
            "language": result["language"],
            "segments": result.get("segments", [])
        })
    finally:
        # Nettoyer le fichier temporaire
        os.unlink(tmp_path)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000)
```

### √âtape 2 : Cr√©er un Dockerfile

Cr√©ez un fichier `Dockerfile` :

```dockerfile
FROM python:3.11-slim

# Installer les d√©pendances syst√®me
RUN apt-get update && apt-get install -y \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Installer les d√©pendances Python
RUN pip install --no-cache-dir \
    openai-whisper \
    flask \
    flask-cors

# Copier le serveur
COPY whisper-server.py /app/whisper-server.py

WORKDIR /app

# Exposer le port
EXPOSE 8000

# D√©marrer le serveur
CMD ["python", "whisper-server.py"]
```

### √âtape 3 : D√©ployer avec Docker

```bash
# Construire l'image
docker build -t pilotys-whisper .

# Lancer le conteneur
docker run -d \
  --name pilotys-whisper \
  -p 8000:8000 \
  --restart unless-stopped \
  pilotys-whisper
```

### √âtape 4 : Configurer PILOTYS

Dans vos variables d'environnement (`.env.local` ou Vercel) :

```env
WHISPER_API_URL=http://votre-serveur-ip:8000
# Ou avec un domaine :
WHISPER_API_URL=https://whisper.votre-domaine.com

# Optionnel : cl√© API pour s√©curiser l'acc√®s
WHISPER_API_KEY=votre_cle_secrete_ici
```

## Option 2 : D√©ploiement avec Python directement

### Sur votre serveur Linux

```bash
# Installer Python et les d√©pendances
sudo apt-get update
sudo apt-get install -y python3-pip ffmpeg

# Installer Whisper
pip3 install openai-whisper flask flask-cors

# Cr√©er le fichier whisper-server.py (voir Option 1)

# Lancer avec systemd (pour qu'il d√©marre automatiquement)
sudo nano /etc/systemd/system/whisper.service
```

Contenu de `/etc/systemd/system/whisper.service` :

```ini
[Unit]
Description=PILOTYS Whisper Server
After=network.target

[Service]
Type=simple
User=votre-utilisateur
WorkingDirectory=/chemin/vers/whisper
ExecStart=/usr/bin/python3 /chemin/vers/whisper/whisper-server.py
Restart=always

[Install]
WantedBy=multi-user.target
```

Puis :

```bash
sudo systemctl enable whisper
sudo systemctl start whisper
```

## Option 3 : D√©ploiement sur Vercel (avec limitations)

**Note** : Vercel a des limitations de temps d'ex√©cution (10s pour Hobby, 60s pour Pro). Whisper peut prendre plus de temps pour les longs audios.

Pour Vercel, utilisez plut√¥t une API route qui appelle votre serveur Whisper externe.

## S√©curit√©

### 1. Authentification (Recommand√©)

Modifiez `whisper-server.py` pour ajouter une authentification :

```python
from functools import wraps

API_KEY = os.getenv("WHISPER_API_KEY", "")

def require_api_key(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if API_KEY:
            auth_header = request.headers.get("Authorization", "")
            if not auth_header.startswith("Bearer ") or auth_header.split(" ")[1] != API_KEY:
                return jsonify({"error": "Non autoris√©"}), 401
        return f(*args, **kwargs)
    return decorated_function

@app.route("/transcribe", methods=["POST"])
@require_api_key
def transcribe():
    # ... code existant
```

### 2. HTTPS (Recommand√©)

Utilisez un reverse proxy avec SSL (Nginx, Caddy) :

```nginx
server {
    listen 443 ssl;
    server_name whisper.votre-domaine.com;
    
    ssl_certificate /chemin/vers/cert.pem;
    ssl_certificate_key /chemin/vers/key.pem;
    
    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### 3. Firewall

Limitez l'acc√®s √† votre serveur Whisper :

```bash
# Autoriser uniquement depuis Vercel (ou votre IP)
sudo ufw allow from VERCEL_IP to any port 8000
sudo ufw enable
```

## Mod√®les Whisper disponibles

| Mod√®le | Taille | RAM requise | Vitesse | Qualit√© |
|--------|--------|-------------|---------|---------|
| tiny | 39MB | ~1GB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| base | 74MB | ~1GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| small | 244MB | ~2GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| medium | 769MB | ~5GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| large | 1550MB | ~10GB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

**Recommandation** : Commencez avec `base` (bon √©quilibre vitesse/qualit√©).

Pour changer le mod√®le, modifiez dans `whisper-server.py` :
```python
model = whisper.load_model("base")  # Changez "base" par le mod√®le souhait√©
```

## Performance

### Avec CPU uniquement
- **base** : ~1-2x la dur√©e de l'audio (30 min d'audio = 30-60 min de traitement)
- **small** : ~2-3x la dur√©e de l'audio

### Avec GPU (NVIDIA)
- **base** : ~0.1x la dur√©e de l'audio (30 min = 3 min de traitement)
- **small** : ~0.2x la dur√©e de l'audio

**Recommandation** : Utilisez un GPU si vous avez beaucoup de transcriptions.

## Co√ªts d'h√©bergement

### Option √©conomique (CPU uniquement)
- **OVH VPS** : ~5‚Ç¨/mois (4GB RAM)
- **Scaleway** : ~6‚Ç¨/mois (4GB RAM)
- **Hetzner** : ~4‚Ç¨/mois (4GB RAM)

### Option performante (avec GPU)
- **Vast.ai** : ~0.20‚Ç¨/heure (GPU partag√©)
- **RunPod** : ~0.30‚Ç¨/heure (GPU d√©di√©)
- **AWS EC2 g4dn** : ~0.50‚Ç¨/heure

Pour un usage mod√©r√© (quelques heures de transcription/mois), un VPS CPU suffit.

## Test de votre serveur

```bash
# V√©rifier que le serveur r√©pond
curl http://votre-serveur:8000/health

# Tester la transcription (remplacez par votre fichier audio)
curl -X POST \
  -F "file=@test-audio.mp3" \
  http://votre-serveur:8000/transcribe
```

## Configuration dans PILOTYS

Une fois votre serveur d√©ploy√©, configurez dans PILOTYS :

**En local** (`.env.local`) :
```env
WHISPER_API_URL=http://localhost:8000
# Ou avec votre domaine :
WHISPER_API_URL=https://whisper.votre-domaine.com

# Optionnel : cl√© API pour s√©curiser
WHISPER_API_KEY=votre_cle_secrete_ici

# Optionnel : mod√®le √† utiliser
WHISPER_MODEL=base
WHISPER_LANGUAGE=fr
```

**Sur Vercel** :
- Ajoutez `WHISPER_API_URL` avec l'URL de votre serveur
- Ajoutez `WHISPER_API_KEY` si vous avez activ√© l'authentification
- Red√©ployez l'application

## Monitoring

Ajoutez des logs dans votre serveur Whisper pour surveiller :

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.route("/transcribe", methods=["POST"])
def transcribe():
    logger.info(f"Transcription demand√©e: {request.files['file'].filename}")
    # ... reste du code
    logger.info(f"Transcription termin√©e: {len(result['text'])} caract√®res")
```

## D√©pannage

### Le serveur ne r√©pond pas

1. V√©rifiez que le service tourne : `sudo systemctl status whisper`
2. V√©rifiez les logs : `sudo journalctl -u whisper -f`
3. V√©rifiez le firewall : `sudo ufw status`

### Transcription lente

1. Utilisez un mod√®le plus petit (`tiny` ou `base`)
2. Ajoutez un GPU si possible
3. Optimisez la qualit√© audio avant l'envoi

### Erreur "Out of memory"

1. Utilisez un mod√®le plus petit
2. Augmentez la RAM du serveur
3. Traitez les fichiers par petits morceaux

## Support

Si vous avez besoin d'aide pour d√©ployer votre serveur Whisper, consultez :
- Documentation Whisper : https://github.com/openai/whisper
- Documentation Flask : https://flask.palletsprojects.com/

